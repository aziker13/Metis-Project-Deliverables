{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "101a0f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.4.60-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 60.3 MB 9.4 MB/s eta 0:00:011     |████████████████████████████████| 60.1 MB 9.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in ./anaconda3/envs/metis/lib/python3.8/site-packages (from opencv-python) (1.19.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.4.60\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9622d67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 16:42:02.181157: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/aziker/anaconda3/envs/metis/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2021-11-30 16:42:02.181216: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80446305",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Leaf_outlines/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c80e1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "ground_truth = []\n",
    "for img in os.listdir(path):\n",
    "    pic = cv2.imread(os.path.join(path,img))\n",
    "    pic = cv2.cvtColor(pic,cv2.COLOR_BGR2RGB)\n",
    "    pic = cv2.resize(pic,(80,80))\n",
    "    training_data.append([pic])\n",
    "    ground_truth.append(img[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3d7ee1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pset'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7dc164d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Pset': 0,\n",
       " 'Pker': 1,\n",
       " 'Pcoc': 2,\n",
       " 'Pmin': 3,\n",
       " 'Prub': 4,\n",
       " 'Pmis': 5,\n",
       " 'Pmal': 6,\n",
       " 'Pcor': 7,\n",
       " 'Pmie': 8,\n",
       " 'Pmuc': 9,\n",
       " 'Pcri': 10,\n",
       " 'Psid': 11,\n",
       " 'Pfoe': 12,\n",
       " 'Pgib': 13,\n",
       " 'Pmol': 14,\n",
       " 'Prac': 15,\n",
       " 'Pala': 16,\n",
       " 'Psub': 17,\n",
       " 'Pedm': 18,\n",
       " 'Phat': 19,\n",
       " 'Ptlo': 20,\n",
       " 'Pbif': 21,\n",
       " 'Pgra': 22,\n",
       " 'Pcap': 23,\n",
       " 'Pvil': 24,\n",
       " 'Ptri': 25,\n",
       " 'Pmic': 26,\n",
       " 'Pmaf': 27,\n",
       " 'Pame': 28,\n",
       " 'Porg': 29,\n",
       " 'Pact': 30,\n",
       " 'Pcae': 31,\n",
       " 'Pcin': 32,\n",
       " 'Plig': 33,\n",
       " 'Pten': 34,\n",
       " 'Pgal': 35,\n",
       " 'Ppoh': 36,\n",
       " 'Pmor': 37,\n",
       " 'Pnit': 38,\n",
       " 'Pedu': 39}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Need to make integers for to_categorical later, ignoring pfii because it will merge with Pfoe later\n",
    "d = {}\n",
    "counter = 0\n",
    "for i in ground_truth:\n",
    "    if i[:4] == 'Pfii':\n",
    "        continue\n",
    "    elif i not in d.keys():\n",
    "        d[i] = counter\n",
    "        counter += 1\n",
    "    else:\n",
    "        continue\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47872e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(path,'leaf_images'),np.array(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d20052c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(path,'leaf_truths'),np.array(ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bd277ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5637ffe130>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.array(training_data[0]).reshape(80,80,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16b1149f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7516c43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'image': training_data, 'species': ground_truth}\n",
    "df = pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3654e0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''in read.me of original data, Pfii and Pfoe both represent the same\n",
    "    species, relabelling to reflect this'''                   \n",
    "df.species.replace({'Pfii': 'Pfoe'}, inplace=True)                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4204f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rep#54lacing species name with integer value for later conversion to categoricals\n",
    "df.species.replace(d, inplace=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f8e063a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.species.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "66ce1b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4cd6366ee0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.array(df.image[0]).reshape(80,80,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39a03433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "X_vals, y_vals = np.array(training_data), df.species.astype(np.int64)\n",
    "\n",
    "# 28x28 images, with grey scale pixel strengths repeated across 3 channels for color representation\n",
    "X_vals = X_vals.reshape((-1,80,80,3)) \n",
    "### REPEAT VALUES ACROSS 2 ADDITIONAL CHANNELS\n",
    "\n",
    "X_train, X_test, y_train, y_test = (train_test_split(X_vals, y_vals, \n",
    "                                                     test_size = .2, random_state = 42))\n",
    "\n",
    "# 2D (one-hot encoded) representation of multiclass target \n",
    "y_train_cat = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e40194d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2635, 40)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "396d9513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_vals[345]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "17db6922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3294, 40)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.get_dummies(df.species)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88ae4b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 80, 80, 30)        840       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 40, 40, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 40, 40, 60)        16260     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 20, 20, 60)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 20, 20, 90)        48690     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 90)                0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 90)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 80)                7280      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 40)                3240      \n",
      "=================================================================\n",
      "Total params: 76,310\n",
      "Trainable params: 76,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 8s 119ms/step - loss: 6.2823 - accuracy: 0.0461 - val_loss: 3.5808 - val_accuracy: 0.0425\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 8s 122ms/step - loss: 3.5322 - accuracy: 0.0653 - val_loss: 3.4589 - val_accuracy: 0.1335\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 7s 116ms/step - loss: 3.3268 - accuracy: 0.1113 - val_loss: 3.2229 - val_accuracy: 0.1563\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 7s 116ms/step - loss: 3.1188 - accuracy: 0.1473 - val_loss: 3.0375 - val_accuracy: 0.1624\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 7s 114ms/step - loss: 2.8658 - accuracy: 0.1984 - val_loss: 2.8137 - val_accuracy: 0.1973\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 2.6767 - accuracy: 0.2282 - val_loss: 2.6275 - val_accuracy: 0.2489\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 2.4512 - accuracy: 0.2895 - val_loss: 2.4442 - val_accuracy: 0.2914\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 2.2980 - accuracy: 0.3143 - val_loss: 2.3168 - val_accuracy: 0.3065\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 2.1460 - accuracy: 0.3568 - val_loss: 2.2827 - val_accuracy: 0.3445\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 2.0115 - accuracy: 0.3963 - val_loss: 2.1501 - val_accuracy: 0.3703\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 1.8816 - accuracy: 0.4236 - val_loss: 2.0661 - val_accuracy: 0.3687\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 1.7787 - accuracy: 0.4519 - val_loss: 2.0387 - val_accuracy: 0.3945\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 1.7011 - accuracy: 0.4793 - val_loss: 1.8967 - val_accuracy: 0.4507\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 1.6360 - accuracy: 0.4980 - val_loss: 1.8768 - val_accuracy: 0.4370\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 1.5491 - accuracy: 0.5268 - val_loss: 1.8286 - val_accuracy: 0.4613\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 1.5640 - accuracy: 0.5121 - val_loss: 1.7928 - val_accuracy: 0.4659\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 1.4409 - accuracy: 0.5445 - val_loss: 1.9299 - val_accuracy: 0.4158\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 1.3634 - accuracy: 0.5628 - val_loss: 1.7406 - val_accuracy: 0.4674\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 7s 111ms/step - loss: 1.3149 - accuracy: 0.5840 - val_loss: 1.7563 - val_accuracy: 0.4856\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 7s 116ms/step - loss: 1.2632 - accuracy: 0.5941 - val_loss: 1.7062 - val_accuracy: 0.4962\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 9s 138ms/step - loss: 1.2339 - accuracy: 0.6027 - val_loss: 1.5926 - val_accuracy: 0.5266\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 9s 143ms/step - loss: 1.1949 - accuracy: 0.6144 - val_loss: 1.6243 - val_accuracy: 0.5220\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 7s 114ms/step - loss: 1.1413 - accuracy: 0.6225 - val_loss: 1.5576 - val_accuracy: 0.5266\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 6s 102ms/step - loss: 1.1108 - accuracy: 0.6346 - val_loss: 1.5877 - val_accuracy: 0.5569\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 6s 103ms/step - loss: 1.0600 - accuracy: 0.6559 - val_loss: 1.7695 - val_accuracy: 0.4795\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 6s 102ms/step - loss: 1.0535 - accuracy: 0.6574 - val_loss: 1.6500 - val_accuracy: 0.5311\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 6s 102ms/step - loss: 0.9714 - accuracy: 0.6989 - val_loss: 1.7606 - val_accuracy: 0.5296\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 6s 102ms/step - loss: 0.9939 - accuracy: 0.6685 - val_loss: 1.7326 - val_accuracy: 0.5266\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 6s 103ms/step - loss: 0.9194 - accuracy: 0.6928 - val_loss: 1.6806 - val_accuracy: 0.5539\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 7s 109ms/step - loss: 0.8734 - accuracy: 0.7156 - val_loss: 1.5263 - val_accuracy: 0.5736\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 8s 121ms/step - loss: 0.9028 - accuracy: 0.7014 - val_loss: 1.6622 - val_accuracy: 0.5524\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 7s 116ms/step - loss: 0.8060 - accuracy: 0.7363 - val_loss: 1.6402 - val_accuracy: 0.5857\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 7s 121ms/step - loss: 0.8073 - accuracy: 0.7338 - val_loss: 1.6285 - val_accuracy: 0.5326\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 7s 111ms/step - loss: 0.8168 - accuracy: 0.7267 - val_loss: 1.7271 - val_accuracy: 0.5736\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 7s 110ms/step - loss: 0.7928 - accuracy: 0.7439 - val_loss: 1.6122 - val_accuracy: 0.5721\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 7s 110ms/step - loss: 0.7205 - accuracy: 0.7632 - val_loss: 1.5612 - val_accuracy: 0.5645\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 7s 114ms/step - loss: 0.7299 - accuracy: 0.7601 - val_loss: 1.6711 - val_accuracy: 0.5706\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 6s 103ms/step - loss: 0.6986 - accuracy: 0.7652 - val_loss: 1.7143 - val_accuracy: 0.5584\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 6s 103ms/step - loss: 0.6837 - accuracy: 0.7773 - val_loss: 1.7118 - val_accuracy: 0.5690\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 6s 103ms/step - loss: 0.6849 - accuracy: 0.7702 - val_loss: 1.6873 - val_accuracy: 0.5675\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 6s 102ms/step - loss: 0.6599 - accuracy: 0.7763 - val_loss: 1.6374 - val_accuracy: 0.5781\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 6s 103ms/step - loss: 0.7263 - accuracy: 0.7606 - val_loss: 1.7376 - val_accuracy: 0.5903\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 6s 103ms/step - loss: 0.6733 - accuracy: 0.7753 - val_loss: 1.6717 - val_accuracy: 0.5736\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 6s 102ms/step - loss: 0.5596 - accuracy: 0.8198 - val_loss: 1.7620 - val_accuracy: 0.5630\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 6s 102ms/step - loss: 0.5499 - accuracy: 0.8239 - val_loss: 1.6767 - val_accuracy: 0.5873\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 6s 102ms/step - loss: 0.5178 - accuracy: 0.8335 - val_loss: 1.7313 - val_accuracy: 0.5706\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 6s 103ms/step - loss: 0.5634 - accuracy: 0.8102 - val_loss: 1.8443 - val_accuracy: 0.5660\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 6s 102ms/step - loss: 0.5019 - accuracy: 0.8376 - val_loss: 1.8757 - val_accuracy: 0.5539\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 6s 103ms/step - loss: 0.4775 - accuracy: 0.8350 - val_loss: 1.7411 - val_accuracy: 0.5857\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 6s 103ms/step - loss: 0.5141 - accuracy: 0.8305 - val_loss: 1.7850 - val_accuracy: 0.5827\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 6s 102ms/step - loss: 0.4463 - accuracy: 0.8487 - val_loss: 1.8067 - val_accuracy: 0.5797\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 0.4467 - accuracy: 0.8497 - val_loss: 1.7870 - val_accuracy: 0.5766\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 8s 124ms/step - loss: 0.4139 - accuracy: 0.8608 - val_loss: 1.9083 - val_accuracy: 0.5964\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 7s 112ms/step - loss: 0.3857 - accuracy: 0.8745 - val_loss: 1.9241 - val_accuracy: 0.5857\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 7s 112ms/step - loss: 0.4399 - accuracy: 0.8583 - val_loss: 2.0823 - val_accuracy: 0.5706\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 7s 115ms/step - loss: 0.4269 - accuracy: 0.8543 - val_loss: 2.0825 - val_accuracy: 0.5888\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 7s 117ms/step - loss: 0.3823 - accuracy: 0.8796 - val_loss: 1.9459 - val_accuracy: 0.5888\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 7s 109ms/step - loss: 0.3783 - accuracy: 0.8785 - val_loss: 1.9829 - val_accuracy: 0.5948\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 8s 129ms/step - loss: 0.4242 - accuracy: 0.8603 - val_loss: 1.8928 - val_accuracy: 0.6206\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 7s 114ms/step - loss: 0.3508 - accuracy: 0.8957 - val_loss: 2.3108 - val_accuracy: 0.5690\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 7s 112ms/step - loss: 0.3646 - accuracy: 0.8796 - val_loss: 2.0593 - val_accuracy: 0.5903\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 7s 118ms/step - loss: 0.4448 - accuracy: 0.8629 - val_loss: 2.4893 - val_accuracy: 0.5478\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 7s 109ms/step - loss: 0.3934 - accuracy: 0.8704 - val_loss: 2.0058 - val_accuracy: 0.5964\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 7s 111ms/step - loss: 0.2769 - accuracy: 0.9099 - val_loss: 2.0197 - val_accuracy: 0.5964\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 7s 109ms/step - loss: 0.2561 - accuracy: 0.9185 - val_loss: 2.1193 - val_accuracy: 0.6009\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 7s 109ms/step - loss: 0.2263 - accuracy: 0.9281 - val_loss: 2.1421 - val_accuracy: 0.6009\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 7s 110ms/step - loss: 0.2719 - accuracy: 0.9165 - val_loss: 2.3010 - val_accuracy: 0.5524\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 0.2687 - accuracy: 0.9089 - val_loss: 2.0991 - val_accuracy: 0.6100\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 7s 109ms/step - loss: 0.2857 - accuracy: 0.9140 - val_loss: 2.3359 - val_accuracy: 0.5827\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 0.3092 - accuracy: 0.9074 - val_loss: 2.1905 - val_accuracy: 0.6055\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 0.3737 - accuracy: 0.8957 - val_loss: 2.4095 - val_accuracy: 0.5599\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 0.4015 - accuracy: 0.8730 - val_loss: 2.2922 - val_accuracy: 0.5827\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 0.2316 - accuracy: 0.9302 - val_loss: 2.1502 - val_accuracy: 0.5994\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 0.1882 - accuracy: 0.9459 - val_loss: 2.4030 - val_accuracy: 0.5979\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 8s 130ms/step - loss: 0.1652 - accuracy: 0.9529 - val_loss: 2.3368 - val_accuracy: 0.5903\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 7s 116ms/step - loss: 0.1803 - accuracy: 0.9469 - val_loss: 2.2857 - val_accuracy: 0.6191\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 7s 112ms/step - loss: 0.1431 - accuracy: 0.9565 - val_loss: 2.3784 - val_accuracy: 0.6115\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 8s 132ms/step - loss: 0.1291 - accuracy: 0.9636 - val_loss: 2.4110 - val_accuracy: 0.6297\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 7s 118ms/step - loss: 0.1196 - accuracy: 0.9686 - val_loss: 2.5458 - val_accuracy: 0.6100\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 8s 130ms/step - loss: 0.1036 - accuracy: 0.9727 - val_loss: 2.5878 - val_accuracy: 0.6176\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 7s 111ms/step - loss: 0.1268 - accuracy: 0.9646 - val_loss: 2.7396 - val_accuracy: 0.5721\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 7s 118ms/step - loss: 0.1423 - accuracy: 0.9580 - val_loss: 2.4907 - val_accuracy: 0.5933\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 7s 110ms/step - loss: 0.0992 - accuracy: 0.9767 - val_loss: 2.6187 - val_accuracy: 0.5781\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 8s 126ms/step - loss: 0.0878 - accuracy: 0.9793 - val_loss: 2.5954 - val_accuracy: 0.6282\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 7s 115ms/step - loss: 0.1066 - accuracy: 0.9722 - val_loss: 2.8819 - val_accuracy: 0.5842\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 0.4285 - accuracy: 0.8684 - val_loss: 2.7693 - val_accuracy: 0.5706\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 0.3385 - accuracy: 0.9049 - val_loss: 2.5100 - val_accuracy: 0.6055\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 7s 109ms/step - loss: 0.2932 - accuracy: 0.9195 - val_loss: 2.5465 - val_accuracy: 0.5933\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 0.2146 - accuracy: 0.9347 - val_loss: 2.7121 - val_accuracy: 0.5402\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 7s 109ms/step - loss: 0.2901 - accuracy: 0.9018 - val_loss: 2.4990 - val_accuracy: 0.5584\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 0.2011 - accuracy: 0.9423 - val_loss: 2.7619 - val_accuracy: 0.5857\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 7s 109ms/step - loss: 0.1244 - accuracy: 0.9641 - val_loss: 2.5963 - val_accuracy: 0.6009\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 7s 109ms/step - loss: 0.0898 - accuracy: 0.9757 - val_loss: 2.9041 - val_accuracy: 0.5781\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 0.0749 - accuracy: 0.9803 - val_loss: 2.5970 - val_accuracy: 0.6206\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 7s 109ms/step - loss: 0.0548 - accuracy: 0.9868 - val_loss: 2.7309 - val_accuracy: 0.6206\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 7s 109ms/step - loss: 0.0500 - accuracy: 0.9889 - val_loss: 2.7098 - val_accuracy: 0.6267\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 7s 109ms/step - loss: 0.0433 - accuracy: 0.9934 - val_loss: 2.7626 - val_accuracy: 0.6388\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 7s 109ms/step - loss: 0.0465 - accuracy: 0.9873 - val_loss: 2.8457 - val_accuracy: 0.6297\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 7s 109ms/step - loss: 0.0441 - accuracy: 0.9914 - val_loss: 2.8751 - val_accuracy: 0.6206\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 7s 109ms/step - loss: 0.0373 - accuracy: 0.9914 - val_loss: 2.9135 - val_accuracy: 0.6222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f55f996d8b0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D, InputLayer\n",
    "'''\n",
    " In this network structure, note that we follow the typical CNN heuristic of \n",
    " gradually reducing width and height dimenions over time with max pooling\n",
    " (typically by a factor of 2), but increasing the filter depth dimension \n",
    " to find increasingly specific patterns. These models are typically compromised \n",
    " of a series of convolutional blocks followed by a flattening operation and \n",
    " a series of fully connected layers at the terminus.\n",
    "'''\n",
    "\n",
    "NN = Sequential()\n",
    "\n",
    "NN.add(InputLayer(input_shape=X_train.shape[1:]))\n",
    "\n",
    "# Conv block 1.  You can add more conv steps to\n",
    "# each block to increase model capacity.\n",
    "NN.add(Conv2D(filters=30, kernel_size=3, activation='relu', padding='same'))\n",
    "# NN.add(Conv2D(filters=16, kernel_size=3, activation='relu', padding='same'))\n",
    "NN.add(MaxPooling2D())\n",
    "\n",
    "# Conv block 2 - note we increase filter dimension as we move\n",
    "# further into the network. You can add more conv steps to\n",
    "# each block to increase model capacity.\n",
    "NN.add(Conv2D(filters=60, kernel_size=3, activation='relu', padding='same'))\n",
    "# NN.add(Conv2D(filters=16, kernel_size=3, activation='relu', padding='same'))\n",
    "NN.add(MaxPooling2D())\n",
    "\n",
    "# Conv block 3 - The conv blocks should be ended with either a flatten\n",
    "# layer or a global pooling layer. These transform the 2D layers to 1D\n",
    "# to match the following dense layers.\n",
    "NN.add(Conv2D(filters=90, kernel_size=3, activation='relu', padding='same'))\n",
    "\n",
    "NN.add(GlobalAveragePooling2D())\n",
    "\n",
    "# Fully connected block - flattening followed by dense and output layers\n",
    "NN.add(Flatten())\n",
    "NN.add(Dense(80, activation='relu'))\n",
    "NN.add(Dense(40, activation='softmax'))  # 40 target classes\n",
    "\n",
    "NN.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "NN.summary()\n",
    "NN.fit(X_train, y_train_cat, epochs=100, verbose=1, validation_split=0.25,\n",
    "       callbacks=[\n",
    "           keras.callbacks.ModelCheckpoint(\n",
    "               'models/mnist.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "               save_best_only=True)\n",
    "       ])  # track progress as we fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3897c435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6312594840667678"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "preds = np.argmax(NN.predict(X_test), axis=1)\n",
    "accuracy_score(y_test, preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24ccb309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'confusion matrix')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "lr_confusion = confusion_matrix(y_test, preds)\n",
    "lr_confusion\n",
    "\n",
    "sns.set(rc={'figure.figsize':(10,7)})\n",
    "sns.heatmap(lr_confusion, cmap=plt.cm.Blues,fmt='d', square=True,);\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebec52f",
   "metadata": {},
   "source": [
    "We have a basic model up and running that demonstrates learning over the epochs, but also seeing some serious overfitting.  First step will be to adjust the architecture via transfer learning and see if a new architecture will improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e988b8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import mobilenet_v2\n",
    "\n",
    "base_model = mobilenet_v2.MobileNetV2(\n",
    "    weights='imagenet',\n",
    "    input_shape=(80, 80, 3),\n",
    "    include_top=False)  \n",
    "\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3bd3720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(80, 80, 3))\n",
    "\n",
    "x = base_model(inputs, training=False)\n",
    "\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = keras.layers.Dense(units=80, activation = 'relu')(x)\n",
    "\n",
    "outputs = keras.layers.Dense(units=40, activation = 'softmax')(x)\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32853c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 80, 80, 3)]       0         \n",
      "_________________________________________________________________\n",
      "mobilenetv2_1.00_224 (Functi (None, 3, 3, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_5 ( (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 80)                102480    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 40)                3240      \n",
      "=================================================================\n",
      "Total params: 2,363,704\n",
      "Trainable params: 105,720\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 6s 62ms/step - loss: 3.3287 - accuracy: 0.1513 - val_loss: 2.8616 - val_accuracy: 0.2580\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.6317 - accuracy: 0.2804 - val_loss: 2.5733 - val_accuracy: 0.2792\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 2.3417 - accuracy: 0.3381 - val_loss: 2.3740 - val_accuracy: 0.3369\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.1681 - accuracy: 0.3780 - val_loss: 2.2875 - val_accuracy: 0.3824\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 2.0082 - accuracy: 0.4226 - val_loss: 2.1855 - val_accuracy: 0.3763\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.9458 - accuracy: 0.4297 - val_loss: 2.1986 - val_accuracy: 0.3536\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 3s 56ms/step - loss: 1.8607 - accuracy: 0.4529 - val_loss: 2.1286 - val_accuracy: 0.3703\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 1.7662 - accuracy: 0.4793 - val_loss: 2.1192 - val_accuracy: 0.3687\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 1.7334 - accuracy: 0.4889 - val_loss: 2.0479 - val_accuracy: 0.4279\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.6753 - accuracy: 0.5066 - val_loss: 1.9726 - val_accuracy: 0.4279\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 1.6372 - accuracy: 0.5046 - val_loss: 2.0564 - val_accuracy: 0.3976\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 1.6152 - accuracy: 0.5192 - val_loss: 1.9875 - val_accuracy: 0.4188\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 5s 75ms/step - loss: 1.5334 - accuracy: 0.5385 - val_loss: 1.9176 - val_accuracy: 0.4385\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 4s 64ms/step - loss: 1.5200 - accuracy: 0.5471 - val_loss: 1.9444 - val_accuracy: 0.4431\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 1.4780 - accuracy: 0.5521 - val_loss: 1.9740 - val_accuracy: 0.4537\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 4s 64ms/step - loss: 1.4675 - accuracy: 0.5541 - val_loss: 1.9563 - val_accuracy: 0.4279\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 1.4464 - accuracy: 0.5653 - val_loss: 1.9830 - val_accuracy: 0.4355\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 1.4093 - accuracy: 0.5668 - val_loss: 1.9573 - val_accuracy: 0.4325\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 4s 60ms/step - loss: 1.3869 - accuracy: 0.5739 - val_loss: 1.9936 - val_accuracy: 0.4461\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.3694 - accuracy: 0.5840 - val_loss: 1.9254 - val_accuracy: 0.4492\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 1.3215 - accuracy: 0.6007 - val_loss: 1.9243 - val_accuracy: 0.4492\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.3308 - accuracy: 0.6032 - val_loss: 1.9916 - val_accuracy: 0.4294\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.2655 - accuracy: 0.6179 - val_loss: 1.8941 - val_accuracy: 0.4810\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.2759 - accuracy: 0.6215 - val_loss: 1.9628 - val_accuracy: 0.4552\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.2702 - accuracy: 0.6179 - val_loss: 1.9354 - val_accuracy: 0.4537\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.2613 - accuracy: 0.6250 - val_loss: 1.9490 - val_accuracy: 0.4370\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.2244 - accuracy: 0.6412 - val_loss: 1.9566 - val_accuracy: 0.4568\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.2246 - accuracy: 0.6311 - val_loss: 2.0036 - val_accuracy: 0.4431\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.1853 - accuracy: 0.6432 - val_loss: 1.9665 - val_accuracy: 0.4689\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 1.1702 - accuracy: 0.6513 - val_loss: 1.9926 - val_accuracy: 0.4294\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 1.1592 - accuracy: 0.6498 - val_loss: 1.9467 - val_accuracy: 0.4643\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.1268 - accuracy: 0.6619 - val_loss: 1.9678 - val_accuracy: 0.4643\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.1216 - accuracy: 0.6675 - val_loss: 1.9945 - val_accuracy: 0.4476\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.1127 - accuracy: 0.6559 - val_loss: 2.0510 - val_accuracy: 0.4279\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.1111 - accuracy: 0.6624 - val_loss: 1.9919 - val_accuracy: 0.4492\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.0845 - accuracy: 0.6726 - val_loss: 1.9774 - val_accuracy: 0.4492\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.1098 - accuracy: 0.6609 - val_loss: 2.0502 - val_accuracy: 0.4461\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.0782 - accuracy: 0.6731 - val_loss: 2.0400 - val_accuracy: 0.4476\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.0514 - accuracy: 0.6827 - val_loss: 1.9940 - val_accuracy: 0.4507\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.0662 - accuracy: 0.6842 - val_loss: 1.9926 - val_accuracy: 0.4613\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.0550 - accuracy: 0.6776 - val_loss: 2.0261 - val_accuracy: 0.4370\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.0211 - accuracy: 0.6933 - val_loss: 2.0970 - val_accuracy: 0.4249\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 1.0422 - accuracy: 0.6837 - val_loss: 2.1310 - val_accuracy: 0.4537\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.9992 - accuracy: 0.7045 - val_loss: 2.0779 - val_accuracy: 0.4522\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.9900 - accuracy: 0.7060 - val_loss: 2.0302 - val_accuracy: 0.4780\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.9912 - accuracy: 0.7095 - val_loss: 2.0879 - val_accuracy: 0.4370\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.9584 - accuracy: 0.7206 - val_loss: 2.0144 - val_accuracy: 0.4628\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.9839 - accuracy: 0.6994 - val_loss: 2.0303 - val_accuracy: 0.4583\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.9603 - accuracy: 0.7080 - val_loss: 2.1502 - val_accuracy: 0.4537\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.9316 - accuracy: 0.7237 - val_loss: 2.0638 - val_accuracy: 0.4507\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.9195 - accuracy: 0.7257 - val_loss: 2.1151 - val_accuracy: 0.4628\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.9208 - accuracy: 0.7277 - val_loss: 2.0745 - val_accuracy: 0.4568\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.9125 - accuracy: 0.7262 - val_loss: 2.1599 - val_accuracy: 0.4492\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.9176 - accuracy: 0.7298 - val_loss: 2.1856 - val_accuracy: 0.4461\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.9252 - accuracy: 0.7262 - val_loss: 2.0568 - val_accuracy: 0.4628\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 4s 69ms/step - loss: 0.9085 - accuracy: 0.7262 - val_loss: 2.1297 - val_accuracy: 0.4537\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 4s 60ms/step - loss: 0.9077 - accuracy: 0.7282 - val_loss: 2.1205 - val_accuracy: 0.4476\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.8777 - accuracy: 0.7454 - val_loss: 2.1864 - val_accuracy: 0.4522\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.9057 - accuracy: 0.7206 - val_loss: 2.1132 - val_accuracy: 0.4507\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.8898 - accuracy: 0.7368 - val_loss: 2.3163 - val_accuracy: 0.4279\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.8806 - accuracy: 0.7368 - val_loss: 2.1782 - val_accuracy: 0.4704\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.8649 - accuracy: 0.7394 - val_loss: 2.1640 - val_accuracy: 0.4780\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.8495 - accuracy: 0.7419 - val_loss: 2.2249 - val_accuracy: 0.4598\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.8324 - accuracy: 0.7454 - val_loss: 2.2619 - val_accuracy: 0.4522\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.8403 - accuracy: 0.7556 - val_loss: 2.2108 - val_accuracy: 0.4431\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.8173 - accuracy: 0.7627 - val_loss: 2.2169 - val_accuracy: 0.4628\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.8184 - accuracy: 0.7581 - val_loss: 2.2468 - val_accuracy: 0.4552\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.8078 - accuracy: 0.7581 - val_loss: 2.2652 - val_accuracy: 0.4492\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.8223 - accuracy: 0.7515 - val_loss: 2.2398 - val_accuracy: 0.4476\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.8015 - accuracy: 0.7581 - val_loss: 2.2350 - val_accuracy: 0.4476\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.8149 - accuracy: 0.7535 - val_loss: 2.2128 - val_accuracy: 0.4643\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.8048 - accuracy: 0.7530 - val_loss: 2.3282 - val_accuracy: 0.4310\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.7914 - accuracy: 0.7662 - val_loss: 2.2716 - val_accuracy: 0.4643\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.7833 - accuracy: 0.7571 - val_loss: 2.3178 - val_accuracy: 0.4598\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.7594 - accuracy: 0.7738 - val_loss: 2.3410 - val_accuracy: 0.4522\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.7834 - accuracy: 0.7667 - val_loss: 2.2781 - val_accuracy: 0.4643\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.7735 - accuracy: 0.7687 - val_loss: 2.2274 - val_accuracy: 0.4583\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.7627 - accuracy: 0.7652 - val_loss: 2.3469 - val_accuracy: 0.4598\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.7711 - accuracy: 0.7677 - val_loss: 2.3265 - val_accuracy: 0.4795\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.7595 - accuracy: 0.7672 - val_loss: 2.4604 - val_accuracy: 0.4537\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.7703 - accuracy: 0.7687 - val_loss: 2.3147 - val_accuracy: 0.4583\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.7269 - accuracy: 0.7849 - val_loss: 2.4489 - val_accuracy: 0.4431\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.7542 - accuracy: 0.7773 - val_loss: 2.3898 - val_accuracy: 0.4446\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 4s 58ms/step - loss: 0.7312 - accuracy: 0.7768 - val_loss: 2.3740 - val_accuracy: 0.4750\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.7484 - accuracy: 0.7723 - val_loss: 2.4383 - val_accuracy: 0.4279\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.7296 - accuracy: 0.7794 - val_loss: 2.3864 - val_accuracy: 0.4598\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.7243 - accuracy: 0.7783 - val_loss: 2.3811 - val_accuracy: 0.4507\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.7205 - accuracy: 0.7839 - val_loss: 2.4169 - val_accuracy: 0.4522\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.6981 - accuracy: 0.7915 - val_loss: 2.5016 - val_accuracy: 0.4492\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.7119 - accuracy: 0.7880 - val_loss: 2.4930 - val_accuracy: 0.4492\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 3s 55ms/step - loss: 0.6924 - accuracy: 0.7859 - val_loss: 2.6430 - val_accuracy: 0.4294\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.7239 - accuracy: 0.7783 - val_loss: 2.4740 - val_accuracy: 0.4461\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.6983 - accuracy: 0.7915 - val_loss: 2.5647 - val_accuracy: 0.4355\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.6644 - accuracy: 0.8041 - val_loss: 2.4549 - val_accuracy: 0.4613\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.6791 - accuracy: 0.7981 - val_loss: 2.4524 - val_accuracy: 0.4492\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.6700 - accuracy: 0.8031 - val_loss: 2.5586 - val_accuracy: 0.4492\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.6830 - accuracy: 0.7930 - val_loss: 2.5446 - val_accuracy: 0.4370\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.7044 - accuracy: 0.7839 - val_loss: 2.5671 - val_accuracy: 0.4431\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.6781 - accuracy: 0.7935 - val_loss: 2.5305 - val_accuracy: 0.4552\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.6642 - accuracy: 0.7910 - val_loss: 2.6853 - val_accuracy: 0.4294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f55e2d20490>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "model.summary()\n",
    "model.fit(X_train, y_train_cat, epochs=100, verbose=1, validation_split=0.25,\n",
    "       callbacks=[\n",
    "           keras.callbacks.ModelCheckpoint(\n",
    "               'models/mnist.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "               save_best_only=True)\n",
    "       ])  # track progress as we fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028430c4",
   "metadata": {},
   "source": [
    "mobilenetV2 performed worse than the base model, will try a more robust model, Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7fa48b9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 8s 0us/step\n",
      "83697664/83683744 [==============================] - 8s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import Xception\n",
    "\n",
    "base_model = Xception(\n",
    "    weights='imagenet',\n",
    "    input_shape=(80, 80, 3),\n",
    "    include_top=False)  \n",
    "\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "07db3316",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(80, 80, 3))\n",
    "\n",
    "x = base_model(inputs, training=False)\n",
    "\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = keras.layers.Dense(units=80, activation = 'relu')(x)\n",
    "\n",
    "outputs = keras.layers.Dense(units=40, activation = 'softmax')(x)\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bda9cf11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 80, 80, 3)]       0         \n",
      "_________________________________________________________________\n",
      "xception (Functional)        (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_6 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 80)                163920    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 40)                3240      \n",
      "=================================================================\n",
      "Total params: 21,028,640\n",
      "Trainable params: 167,160\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 15s 225ms/step - loss: 9.5730 - accuracy: 0.0314 - val_loss: 3.6517 - val_accuracy: 0.0455\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 14s 228ms/step - loss: 3.6518 - accuracy: 0.0349 - val_loss: 3.6421 - val_accuracy: 0.0455\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 15s 243ms/step - loss: 3.6383 - accuracy: 0.0405 - val_loss: 3.6315 - val_accuracy: 0.0440\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 13s 215ms/step - loss: 3.6215 - accuracy: 0.0440 - val_loss: 3.6174 - val_accuracy: 0.0592\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 13s 218ms/step - loss: 3.6163 - accuracy: 0.0445 - val_loss: 3.6073 - val_accuracy: 0.0577\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 15s 240ms/step - loss: 3.6071 - accuracy: 0.0547 - val_loss: 3.5876 - val_accuracy: 0.0577\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 3.5882 - accuracy: 0.0582 - val_loss: 3.5981 - val_accuracy: 0.0561\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 13s 209ms/step - loss: 3.5887 - accuracy: 0.0577 - val_loss: 3.5702 - val_accuracy: 0.0637\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 13s 209ms/step - loss: 3.5658 - accuracy: 0.0567 - val_loss: 3.5584 - val_accuracy: 0.0653\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 3.5559 - accuracy: 0.0587 - val_loss: 3.5432 - val_accuracy: 0.0577\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 13s 212ms/step - loss: 3.5541 - accuracy: 0.0602 - val_loss: 3.5572 - val_accuracy: 0.0668\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 13s 210ms/step - loss: 3.5487 - accuracy: 0.0602 - val_loss: 3.5619 - val_accuracy: 0.0577\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 3.5349 - accuracy: 0.0547 - val_loss: 3.5289 - val_accuracy: 0.0744\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 13s 210ms/step - loss: 3.5233 - accuracy: 0.0607 - val_loss: 3.5019 - val_accuracy: 0.0607\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 13s 213ms/step - loss: 3.5113 - accuracy: 0.0622 - val_loss: 3.4957 - val_accuracy: 0.0592\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 13s 212ms/step - loss: 3.5155 - accuracy: 0.0592 - val_loss: 3.4990 - val_accuracy: 0.0622\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 3.5029 - accuracy: 0.0607 - val_loss: 3.4821 - val_accuracy: 0.0622\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 13s 210ms/step - loss: 3.5019 - accuracy: 0.0597 - val_loss: 3.4695 - val_accuracy: 0.0622\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 13s 209ms/step - loss: 3.4994 - accuracy: 0.0628 - val_loss: 3.4605 - val_accuracy: 0.0622\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 13s 209ms/step - loss: 3.4841 - accuracy: 0.0607 - val_loss: 3.4465 - val_accuracy: 0.0607\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 3.4736 - accuracy: 0.0607 - val_loss: 3.4386 - val_accuracy: 0.0607\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 3.5144 - accuracy: 0.0602 - val_loss: 3.4578 - val_accuracy: 0.0607\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 13s 209ms/step - loss: 3.4739 - accuracy: 0.0622 - val_loss: 3.4317 - val_accuracy: 0.0759\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 3.4761 - accuracy: 0.0633 - val_loss: 3.4728 - val_accuracy: 0.0653\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 13s 209ms/step - loss: 3.4983 - accuracy: 0.0622 - val_loss: 3.4323 - val_accuracy: 0.0622\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 13s 214ms/step - loss: 3.4721 - accuracy: 0.0607 - val_loss: 3.4521 - val_accuracy: 0.0531\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 13s 210ms/step - loss: 3.5170 - accuracy: 0.0592 - val_loss: 3.4469 - val_accuracy: 0.0668\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 13s 209ms/step - loss: 3.4761 - accuracy: 0.0612 - val_loss: 3.4430 - val_accuracy: 0.0546\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 13s 212ms/step - loss: 3.4580 - accuracy: 0.0643 - val_loss: 3.4173 - val_accuracy: 0.0577\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 13s 210ms/step - loss: 3.4338 - accuracy: 0.0622 - val_loss: 3.4109 - val_accuracy: 0.0622\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 13s 210ms/step - loss: 3.4690 - accuracy: 0.0633 - val_loss: 3.4362 - val_accuracy: 0.0637\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 13s 209ms/step - loss: 3.4304 - accuracy: 0.0577 - val_loss: 3.4729 - val_accuracy: 0.0713\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 13s 209ms/step - loss: 3.4246 - accuracy: 0.0683 - val_loss: 3.3956 - val_accuracy: 0.0653\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 13s 209ms/step - loss: 3.3905 - accuracy: 0.0734 - val_loss: 3.3787 - val_accuracy: 0.0744\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 15s 242ms/step - loss: 3.3826 - accuracy: 0.0734 - val_loss: 3.5278 - val_accuracy: 0.0622\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 16s 267ms/step - loss: 3.4038 - accuracy: 0.0719 - val_loss: 3.3687 - val_accuracy: 0.0819\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 16s 265ms/step - loss: 3.4066 - accuracy: 0.0734 - val_loss: 3.3680 - val_accuracy: 0.0653\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 15s 241ms/step - loss: 3.3593 - accuracy: 0.0759 - val_loss: 3.3703 - val_accuracy: 0.0728\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 15s 243ms/step - loss: 3.3778 - accuracy: 0.0759 - val_loss: 3.3699 - val_accuracy: 0.0728\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 16s 251ms/step - loss: 3.3557 - accuracy: 0.0734 - val_loss: 3.3320 - val_accuracy: 0.0683\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 13s 215ms/step - loss: 3.3401 - accuracy: 0.0739 - val_loss: 3.3355 - val_accuracy: 0.0728\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 13s 209ms/step - loss: 3.3573 - accuracy: 0.0744 - val_loss: 3.4190 - val_accuracy: 0.0728\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 13s 208ms/step - loss: 3.3527 - accuracy: 0.0774 - val_loss: 3.3471 - val_accuracy: 0.0637\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 13s 210ms/step - loss: 3.3351 - accuracy: 0.0784 - val_loss: 3.3584 - val_accuracy: 0.0804\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 3.3322 - accuracy: 0.0784 - val_loss: 3.3194 - val_accuracy: 0.0804\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 13s 209ms/step - loss: 3.3159 - accuracy: 0.0754 - val_loss: 3.3126 - val_accuracy: 0.0789\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 13s 210ms/step - loss: 3.3169 - accuracy: 0.0714 - val_loss: 3.3204 - val_accuracy: 0.0744\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 3.2998 - accuracy: 0.0805 - val_loss: 3.3148 - val_accuracy: 0.0926\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 13s 208ms/step - loss: 3.3106 - accuracy: 0.0774 - val_loss: 3.3317 - val_accuracy: 0.0637\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 13s 209ms/step - loss: 3.3096 - accuracy: 0.0850 - val_loss: 3.3273 - val_accuracy: 0.0698\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 13s 209ms/step - loss: 3.3131 - accuracy: 0.0754 - val_loss: 3.3286 - val_accuracy: 0.0865\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 13s 209ms/step - loss: 3.2933 - accuracy: 0.0876 - val_loss: 3.2980 - val_accuracy: 0.0850\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 13s 209ms/step - loss: 3.2961 - accuracy: 0.0906 - val_loss: 3.3432 - val_accuracy: 0.0774\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 13s 210ms/step - loss: 3.2816 - accuracy: 0.0779 - val_loss: 3.2813 - val_accuracy: 0.0774\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 13s 212ms/step - loss: 3.2761 - accuracy: 0.0870 - val_loss: 3.2695 - val_accuracy: 0.0971\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 13s 210ms/step - loss: 3.2942 - accuracy: 0.0881 - val_loss: 3.3283 - val_accuracy: 0.0910\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 3.2707 - accuracy: 0.0800 - val_loss: 3.2805 - val_accuracy: 0.0819\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 13s 210ms/step - loss: 3.2838 - accuracy: 0.0876 - val_loss: 3.2913 - val_accuracy: 0.0789\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 13s 209ms/step - loss: 3.3057 - accuracy: 0.0795 - val_loss: 3.3753 - val_accuracy: 0.0880\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 13s 212ms/step - loss: 3.2518 - accuracy: 0.0845 - val_loss: 3.2248 - val_accuracy: 0.0910\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 13s 209ms/step - loss: 3.2347 - accuracy: 0.0921 - val_loss: 3.2253 - val_accuracy: 0.0986\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 13s 210ms/step - loss: 3.2713 - accuracy: 0.0850 - val_loss: 3.2387 - val_accuracy: 0.1032\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 13s 209ms/step - loss: 3.2504 - accuracy: 0.0906 - val_loss: 3.2354 - val_accuracy: 0.0865\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 13s 209ms/step - loss: 3.2159 - accuracy: 0.0941 - val_loss: 3.2038 - val_accuracy: 0.0986\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 13s 209ms/step - loss: 3.2441 - accuracy: 0.0865 - val_loss: 3.2674 - val_accuracy: 0.0895\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 13s 210ms/step - loss: 3.2243 - accuracy: 0.0997 - val_loss: 3.2843 - val_accuracy: 0.0910\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 13s 209ms/step - loss: 3.2291 - accuracy: 0.0967 - val_loss: 3.2766 - val_accuracy: 0.0910\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 3.1938 - accuracy: 0.1012 - val_loss: 3.1819 - val_accuracy: 0.1017\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 13s 210ms/step - loss: 3.2078 - accuracy: 0.1002 - val_loss: 3.1802 - val_accuracy: 0.1017\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 13s 209ms/step - loss: 3.1934 - accuracy: 0.0977 - val_loss: 3.1745 - val_accuracy: 0.1017\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 13s 210ms/step - loss: 3.1691 - accuracy: 0.1083 - val_loss: 3.1691 - val_accuracy: 0.0986\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 13s 209ms/step - loss: 3.1598 - accuracy: 0.1002 - val_loss: 3.1939 - val_accuracy: 0.1275\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 13s 208ms/step - loss: 3.1771 - accuracy: 0.0987 - val_loss: 3.1615 - val_accuracy: 0.1108\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 13s 209ms/step - loss: 3.1619 - accuracy: 0.1007 - val_loss: 3.1773 - val_accuracy: 0.0895\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 13s 209ms/step - loss: 3.1538 - accuracy: 0.0972 - val_loss: 3.1849 - val_accuracy: 0.1108\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 13s 209ms/step - loss: 3.1482 - accuracy: 0.1083 - val_loss: 3.1553 - val_accuracy: 0.0774\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 13s 211ms/step - loss: 3.1412 - accuracy: 0.1129 - val_loss: 3.1465 - val_accuracy: 0.0895\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 14s 221ms/step - loss: 3.1378 - accuracy: 0.1032 - val_loss: 3.2304 - val_accuracy: 0.1062\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 13s 208ms/step - loss: 3.1641 - accuracy: 0.1017 - val_loss: 3.2366 - val_accuracy: 0.0804\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 13s 209ms/step - loss: 3.1669 - accuracy: 0.0951 - val_loss: 3.1374 - val_accuracy: 0.0895\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 13s 208ms/step - loss: 3.1364 - accuracy: 0.1048 - val_loss: 3.1292 - val_accuracy: 0.1032\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 13s 214ms/step - loss: 3.1392 - accuracy: 0.1027 - val_loss: 3.1474 - val_accuracy: 0.0986\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 15s 238ms/step - loss: 3.1354 - accuracy: 0.1068 - val_loss: 3.2549 - val_accuracy: 0.0653\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 14s 228ms/step - loss: 3.1232 - accuracy: 0.1149 - val_loss: 3.1429 - val_accuracy: 0.0895\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 13s 216ms/step - loss: 3.1150 - accuracy: 0.1113 - val_loss: 3.1255 - val_accuracy: 0.1138\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 14s 231ms/step - loss: 3.1105 - accuracy: 0.1073 - val_loss: 3.1093 - val_accuracy: 0.0941\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 14s 219ms/step - loss: 3.1385 - accuracy: 0.1037 - val_loss: 3.2454 - val_accuracy: 0.0622\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 13s 215ms/step - loss: 3.1194 - accuracy: 0.1083 - val_loss: 3.1548 - val_accuracy: 0.0880\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 13s 218ms/step - loss: 3.1198 - accuracy: 0.1027 - val_loss: 3.1261 - val_accuracy: 0.0971\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 13s 216ms/step - loss: 3.1075 - accuracy: 0.1007 - val_loss: 3.1155 - val_accuracy: 0.0956\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 13s 216ms/step - loss: 3.0861 - accuracy: 0.1078 - val_loss: 3.1320 - val_accuracy: 0.1077\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 13s 215ms/step - loss: 3.0993 - accuracy: 0.1063 - val_loss: 3.1482 - val_accuracy: 0.0744\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 13s 217ms/step - loss: 3.1020 - accuracy: 0.1053 - val_loss: 3.0964 - val_accuracy: 0.0971\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 13s 215ms/step - loss: 3.0865 - accuracy: 0.1037 - val_loss: 3.1056 - val_accuracy: 0.0865\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 13s 215ms/step - loss: 3.0929 - accuracy: 0.1149 - val_loss: 3.1902 - val_accuracy: 0.0835\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 13s 216ms/step - loss: 3.1031 - accuracy: 0.1037 - val_loss: 3.0991 - val_accuracy: 0.0956\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 13s 216ms/step - loss: 3.0799 - accuracy: 0.1129 - val_loss: 3.1077 - val_accuracy: 0.1032\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 13s 215ms/step - loss: 3.0910 - accuracy: 0.1053 - val_loss: 3.0959 - val_accuracy: 0.1153\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 13s 215ms/step - loss: 3.0850 - accuracy: 0.1139 - val_loss: 3.0895 - val_accuracy: 0.0926\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 13s 217ms/step - loss: 3.0679 - accuracy: 0.1088 - val_loss: 3.2682 - val_accuracy: 0.0622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f55e0343520>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "model.summary()\n",
    "model.fit(X_train, y_train_cat, epochs=100, verbose=1, validation_split=0.25,\n",
    "       callbacks=[\n",
    "           keras.callbacks.ModelCheckpoint(\n",
    "               'models/mnist.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "               save_best_only=True)\n",
    "       ])  # track progress as we fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2326bab9",
   "metadata": {},
   "source": [
    "Going back to the base model, and attempting regularization in the dense layer to try and reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d508824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 80, 80, 30)        840       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 40, 40, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 40, 40, 60)        16260     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 20, 20, 60)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 20, 20, 90)        48690     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_8 ( (None, 90)                0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 90)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 80)                7280      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 40)                3240      \n",
      "=================================================================\n",
      "Total params: 76,310\n",
      "Trainable params: 76,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 8s 127ms/step - loss: 7.8214 - accuracy: 0.0304 - val_loss: 4.2269 - val_accuracy: 0.0334\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 9s 139ms/step - loss: 4.0926 - accuracy: 0.0622 - val_loss: 4.0148 - val_accuracy: 0.0971\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 8s 127ms/step - loss: 3.8776 - accuracy: 0.0946 - val_loss: 3.7732 - val_accuracy: 0.1153\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 8s 120ms/step - loss: 3.6588 - accuracy: 0.1245 - val_loss: 3.5287 - val_accuracy: 0.1608\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 3.3759 - accuracy: 0.1549 - val_loss: 3.3422 - val_accuracy: 0.1669\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 3.1420 - accuracy: 0.1807 - val_loss: 3.0824 - val_accuracy: 0.2049\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 2.9040 - accuracy: 0.2384 - val_loss: 2.9412 - val_accuracy: 0.3171\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 2.7217 - accuracy: 0.2950 - val_loss: 2.7340 - val_accuracy: 0.3171\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 7s 105ms/step - loss: 2.5462 - accuracy: 0.3279 - val_loss: 2.6853 - val_accuracy: 0.3414\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 2.4315 - accuracy: 0.3816 - val_loss: 2.5058 - val_accuracy: 0.3263\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 2.2937 - accuracy: 0.3927 - val_loss: 2.4304 - val_accuracy: 0.4006\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 2.2314 - accuracy: 0.4013 - val_loss: 2.3749 - val_accuracy: 0.3961\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 7s 111ms/step - loss: 2.1336 - accuracy: 0.4352 - val_loss: 2.3398 - val_accuracy: 0.3885\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 2.0579 - accuracy: 0.4570 - val_loss: 2.2661 - val_accuracy: 0.4112\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 1.9867 - accuracy: 0.4681 - val_loss: 2.2512 - val_accuracy: 0.3961\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 7s 105ms/step - loss: 1.9182 - accuracy: 0.4909 - val_loss: 2.0334 - val_accuracy: 0.4583\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 1.8259 - accuracy: 0.5121 - val_loss: 1.9970 - val_accuracy: 0.4719\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 1.8084 - accuracy: 0.5162 - val_loss: 2.0094 - val_accuracy: 0.4719\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 7s 105ms/step - loss: 1.7506 - accuracy: 0.5121 - val_loss: 1.9849 - val_accuracy: 0.4795\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 1.7167 - accuracy: 0.5410 - val_loss: 1.9584 - val_accuracy: 0.5008\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 1.6518 - accuracy: 0.5536 - val_loss: 2.0470 - val_accuracy: 0.4568\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 1.6245 - accuracy: 0.5698 - val_loss: 1.9105 - val_accuracy: 0.4992\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 1.5812 - accuracy: 0.5779 - val_loss: 1.9134 - val_accuracy: 0.5038\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 1.5211 - accuracy: 0.5997 - val_loss: 1.9557 - val_accuracy: 0.4841\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 1.4946 - accuracy: 0.5830 - val_loss: 1.8274 - val_accuracy: 0.5114\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 1.4611 - accuracy: 0.6048 - val_loss: 1.8976 - val_accuracy: 0.4947\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 1.4377 - accuracy: 0.6078 - val_loss: 1.8491 - val_accuracy: 0.5114\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 7s 105ms/step - loss: 1.3994 - accuracy: 0.6164 - val_loss: 1.7564 - val_accuracy: 0.5569\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 1.3714 - accuracy: 0.6159 - val_loss: 1.7278 - val_accuracy: 0.5402\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 1.3408 - accuracy: 0.6275 - val_loss: 2.0069 - val_accuracy: 0.4689\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 1.3154 - accuracy: 0.6387 - val_loss: 1.7783 - val_accuracy: 0.5387\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 1.3350 - accuracy: 0.6215 - val_loss: 1.7776 - val_accuracy: 0.5326\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 1.2459 - accuracy: 0.6619 - val_loss: 1.7462 - val_accuracy: 0.5448\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 1.2371 - accuracy: 0.6483 - val_loss: 1.8475 - val_accuracy: 0.5311\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 1.2051 - accuracy: 0.6751 - val_loss: 1.8006 - val_accuracy: 0.5250\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 1.1737 - accuracy: 0.6908 - val_loss: 1.8696 - val_accuracy: 0.4947\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 1.1462 - accuracy: 0.6781 - val_loss: 1.7822 - val_accuracy: 0.5432\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 1.1301 - accuracy: 0.6898 - val_loss: 1.7988 - val_accuracy: 0.5417\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 1.1190 - accuracy: 0.6974 - val_loss: 1.6789 - val_accuracy: 0.5690\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 1.0653 - accuracy: 0.7045 - val_loss: 1.7173 - val_accuracy: 0.5781\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 1.0623 - accuracy: 0.6994 - val_loss: 1.6972 - val_accuracy: 0.5675\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 1.0154 - accuracy: 0.7277 - val_loss: 1.7574 - val_accuracy: 0.5599\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 0.9802 - accuracy: 0.7323 - val_loss: 1.9118 - val_accuracy: 0.5554\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 1.0844 - accuracy: 0.7019 - val_loss: 1.7409 - val_accuracy: 0.5493\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.9940 - accuracy: 0.7293 - val_loss: 1.6928 - val_accuracy: 0.5630\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.9832 - accuracy: 0.7247 - val_loss: 1.8611 - val_accuracy: 0.5387\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 7s 105ms/step - loss: 1.0113 - accuracy: 0.7136 - val_loss: 1.7804 - val_accuracy: 0.5675\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.9762 - accuracy: 0.7227 - val_loss: 1.9065 - val_accuracy: 0.5402\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 0.9430 - accuracy: 0.7293 - val_loss: 1.7061 - val_accuracy: 0.5675\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.8577 - accuracy: 0.7662 - val_loss: 1.7476 - val_accuracy: 0.5933\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.8553 - accuracy: 0.7606 - val_loss: 1.7318 - val_accuracy: 0.5690\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 7s 105ms/step - loss: 0.9277 - accuracy: 0.7424 - val_loss: 1.7906 - val_accuracy: 0.5736\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 0.8710 - accuracy: 0.7546 - val_loss: 1.7994 - val_accuracy: 0.5569\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.8488 - accuracy: 0.7702 - val_loss: 1.7285 - val_accuracy: 0.5812\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.7630 - accuracy: 0.8077 - val_loss: 1.6416 - val_accuracy: 0.6024\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.7746 - accuracy: 0.7935 - val_loss: 1.9371 - val_accuracy: 0.5675\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 7s 105ms/step - loss: 0.8502 - accuracy: 0.7758 - val_loss: 1.8388 - val_accuracy: 0.5827\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.7627 - accuracy: 0.7981 - val_loss: 1.8437 - val_accuracy: 0.5888\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.7284 - accuracy: 0.8062 - val_loss: 1.7751 - val_accuracy: 0.5918\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.8018 - accuracy: 0.7854 - val_loss: 1.8052 - val_accuracy: 0.6070\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 0.7084 - accuracy: 0.8138 - val_loss: 1.7446 - val_accuracy: 0.6070\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.6798 - accuracy: 0.8295 - val_loss: 1.8201 - val_accuracy: 0.5994\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.7700 - accuracy: 0.7885 - val_loss: 1.9461 - val_accuracy: 0.5797\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.7698 - accuracy: 0.7935 - val_loss: 1.9063 - val_accuracy: 0.6115\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.6559 - accuracy: 0.8381 - val_loss: 1.8730 - val_accuracy: 0.5918\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.6265 - accuracy: 0.8462 - val_loss: 1.8584 - val_accuracy: 0.5979\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 7s 105ms/step - loss: 0.6714 - accuracy: 0.8269 - val_loss: 1.9739 - val_accuracy: 0.5918\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.6205 - accuracy: 0.8467 - val_loss: 1.8847 - val_accuracy: 0.5948\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.6421 - accuracy: 0.8365 - val_loss: 1.9404 - val_accuracy: 0.5736\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.5937 - accuracy: 0.8532 - val_loss: 1.9269 - val_accuracy: 0.5873\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.6190 - accuracy: 0.8517 - val_loss: 2.1766 - val_accuracy: 0.5766\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 7s 105ms/step - loss: 0.6586 - accuracy: 0.8370 - val_loss: 1.9454 - val_accuracy: 0.5827\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.5529 - accuracy: 0.8639 - val_loss: 1.9267 - val_accuracy: 0.6100\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.5988 - accuracy: 0.8522 - val_loss: 2.1924 - val_accuracy: 0.5827\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.6289 - accuracy: 0.8462 - val_loss: 2.1391 - val_accuracy: 0.5493\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.5513 - accuracy: 0.8750 - val_loss: 1.9930 - val_accuracy: 0.5857\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 0.6023 - accuracy: 0.8537 - val_loss: 2.0243 - val_accuracy: 0.5948\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 7s 111ms/step - loss: 0.5244 - accuracy: 0.8801 - val_loss: 2.1701 - val_accuracy: 0.5781\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.5099 - accuracy: 0.8816 - val_loss: 1.9474 - val_accuracy: 0.6161\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 6s 103ms/step - loss: 0.4541 - accuracy: 0.9155 - val_loss: 1.9566 - val_accuracy: 0.6191\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 6s 103ms/step - loss: 0.4924 - accuracy: 0.8907 - val_loss: 2.1328 - val_accuracy: 0.5797\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 6s 102ms/step - loss: 0.4871 - accuracy: 0.8882 - val_loss: 2.1431 - val_accuracy: 0.5918\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 6s 102ms/step - loss: 0.4526 - accuracy: 0.9018 - val_loss: 2.2473 - val_accuracy: 0.5599\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 6s 103ms/step - loss: 0.5383 - accuracy: 0.8745 - val_loss: 2.0932 - val_accuracy: 0.5797\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 6s 102ms/step - loss: 0.6687 - accuracy: 0.8355 - val_loss: 2.0818 - val_accuracy: 0.5827\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 6s 103ms/step - loss: 0.4549 - accuracy: 0.8968 - val_loss: 2.2266 - val_accuracy: 0.5873\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 6s 101ms/step - loss: 0.4319 - accuracy: 0.9114 - val_loss: 2.0859 - val_accuracy: 0.6222\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 6s 102ms/step - loss: 0.4180 - accuracy: 0.9160 - val_loss: 2.1551 - val_accuracy: 0.5948\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 6s 102ms/step - loss: 0.4715 - accuracy: 0.8983 - val_loss: 2.5337 - val_accuracy: 0.5766\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 6s 102ms/step - loss: 0.5074 - accuracy: 0.8816 - val_loss: 2.2755 - val_accuracy: 0.5933\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 6s 102ms/step - loss: 0.4269 - accuracy: 0.9155 - val_loss: 2.4479 - val_accuracy: 0.5964\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 6s 102ms/step - loss: 0.4270 - accuracy: 0.9104 - val_loss: 2.5608 - val_accuracy: 0.5721\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 6s 102ms/step - loss: 0.4633 - accuracy: 0.8942 - val_loss: 2.2043 - val_accuracy: 0.6131\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 6s 102ms/step - loss: 0.3955 - accuracy: 0.9231 - val_loss: 2.4122 - val_accuracy: 0.5888\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 6s 104ms/step - loss: 0.4955 - accuracy: 0.8907 - val_loss: 2.2579 - val_accuracy: 0.5948\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 6s 102ms/step - loss: 0.3742 - accuracy: 0.9342 - val_loss: 2.1713 - val_accuracy: 0.5903\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 6s 102ms/step - loss: 0.4595 - accuracy: 0.8993 - val_loss: 2.4022 - val_accuracy: 0.5797\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 6s 102ms/step - loss: 0.4636 - accuracy: 0.8942 - val_loss: 2.5312 - val_accuracy: 0.5569\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 6s 102ms/step - loss: 0.6456 - accuracy: 0.8401 - val_loss: 2.4511 - val_accuracy: 0.5706\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 6s 102ms/step - loss: 0.3713 - accuracy: 0.9332 - val_loss: 2.1662 - val_accuracy: 0.6161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f55e038a580>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "NN = Sequential()\n",
    "\n",
    "NN.add(InputLayer(input_shape=X_train.shape[1:]))\n",
    "\n",
    "\n",
    "NN.add(Conv2D(filters=30, kernel_size=3, activation='relu', padding='same'))\n",
    "\n",
    "NN.add(MaxPooling2D())\n",
    "\n",
    "\n",
    "NN.add(Conv2D(filters=60, kernel_size=3, activation='relu', padding='same'))\n",
    "\n",
    "NN.add(MaxPooling2D())\n",
    "\n",
    "\n",
    "NN.add(Conv2D(filters=90, kernel_size=3, activation='relu', padding='same'))\n",
    "\n",
    "NN.add(GlobalAveragePooling2D())\n",
    "\n",
    "\n",
    "NN.add(Flatten())\n",
    "\n",
    "NN.add(Dense(80, activation='relu', kernel_regularizer='l2'))#added l2 regularizer here\n",
    "\n",
    "NN.add(Dense(40, activation='softmax'))  # 40 target classes\n",
    "\n",
    "NN.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "NN.summary()\n",
    "NN.fit(X_train, y_train_cat, epochs=100, verbose=1, validation_split=0.25,\n",
    "       callbacks=[\n",
    "           keras.callbacks.ModelCheckpoint(\n",
    "               'models/mnist.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "               save_best_only=True)\n",
    "       ])  # track progress as we fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11fb927",
   "metadata": {},
   "source": [
    "accuracy went down for training set but didnt go up for validation, will try regulizer plus dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fcc0d45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 80, 80, 30)        840       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 40, 40, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 40, 40, 60)        16260     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 20, 20, 60)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 20, 20, 90)        48690     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_9 ( (None, 90)                0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 90)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 80)                7280      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 40)                3240      \n",
      "=================================================================\n",
      "Total params: 76,310\n",
      "Trainable params: 76,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 8s 118ms/step - loss: 8.4936 - accuracy: 0.0314 - val_loss: 4.2663 - val_accuracy: 0.0258\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 4.1657 - accuracy: 0.0673 - val_loss: 3.9903 - val_accuracy: 0.1077\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 3.8641 - accuracy: 0.1174 - val_loss: 3.6351 - val_accuracy: 0.1608\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 3.4741 - accuracy: 0.1619 - val_loss: 3.3531 - val_accuracy: 0.1912\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 7s 109ms/step - loss: 3.2351 - accuracy: 0.1959 - val_loss: 3.0504 - val_accuracy: 0.2625\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 3.0486 - accuracy: 0.2272 - val_loss: 2.9579 - val_accuracy: 0.2595\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 2.9106 - accuracy: 0.2581 - val_loss: 2.8843 - val_accuracy: 0.2731\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 2.7737 - accuracy: 0.2753 - val_loss: 2.7369 - val_accuracy: 0.3096\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 7s 115ms/step - loss: 2.6250 - accuracy: 0.3193 - val_loss: 2.6058 - val_accuracy: 0.3429\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 7s 115ms/step - loss: 2.5402 - accuracy: 0.3451 - val_loss: 2.5389 - val_accuracy: 0.3703\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 7s 110ms/step - loss: 2.4248 - accuracy: 0.3770 - val_loss: 2.3876 - val_accuracy: 0.3976\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 2.3311 - accuracy: 0.3932 - val_loss: 2.5098 - val_accuracy: 0.3505\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 7s 109ms/step - loss: 2.2658 - accuracy: 0.3952 - val_loss: 2.3406 - val_accuracy: 0.3854\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 2.1832 - accuracy: 0.4150 - val_loss: 2.2828 - val_accuracy: 0.4158\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 2.0985 - accuracy: 0.4388 - val_loss: 2.1310 - val_accuracy: 0.4492\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 2.0674 - accuracy: 0.4474 - val_loss: 2.1474 - val_accuracy: 0.4492\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 1.9985 - accuracy: 0.4479 - val_loss: 2.1300 - val_accuracy: 0.4294\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 1.9448 - accuracy: 0.4813 - val_loss: 2.0047 - val_accuracy: 0.4886\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 1.8519 - accuracy: 0.4909 - val_loss: 1.9922 - val_accuracy: 0.4750\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 1.8272 - accuracy: 0.5076 - val_loss: 2.1192 - val_accuracy: 0.4416\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 1.7793 - accuracy: 0.5101 - val_loss: 1.9257 - val_accuracy: 0.4932\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 1.7213 - accuracy: 0.5359 - val_loss: 1.9672 - val_accuracy: 0.5023\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 1.6929 - accuracy: 0.5162 - val_loss: 1.9238 - val_accuracy: 0.5175\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 1.6405 - accuracy: 0.5471 - val_loss: 1.8410 - val_accuracy: 0.5175\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 1.6196 - accuracy: 0.5496 - val_loss: 1.9428 - val_accuracy: 0.4659\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 1.5810 - accuracy: 0.5582 - val_loss: 1.8590 - val_accuracy: 0.5159\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 7s 109ms/step - loss: 1.5461 - accuracy: 0.5653 - val_loss: 1.8336 - val_accuracy: 0.5023\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 7s 110ms/step - loss: 1.4858 - accuracy: 0.5774 - val_loss: 1.7687 - val_accuracy: 0.5478\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 1.4875 - accuracy: 0.5749 - val_loss: 1.8301 - val_accuracy: 0.5144\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 1.4194 - accuracy: 0.6032 - val_loss: 1.8728 - val_accuracy: 0.5281\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 7s 110ms/step - loss: 1.4261 - accuracy: 0.5977 - val_loss: 1.7476 - val_accuracy: 0.5190\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 7s 109ms/step - loss: 1.3895 - accuracy: 0.6053 - val_loss: 1.7365 - val_accuracy: 0.5448\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 7s 110ms/step - loss: 1.3324 - accuracy: 0.6078 - val_loss: 1.6879 - val_accuracy: 0.5781\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 7s 109ms/step - loss: 1.3295 - accuracy: 0.6275 - val_loss: 1.8255 - val_accuracy: 0.5448\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 7s 109ms/step - loss: 1.3008 - accuracy: 0.6260 - val_loss: 1.7460 - val_accuracy: 0.5402\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 7s 109ms/step - loss: 1.2597 - accuracy: 0.6493 - val_loss: 1.7068 - val_accuracy: 0.5690\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 1.3347 - accuracy: 0.6225 - val_loss: 1.6593 - val_accuracy: 0.5493\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 7s 109ms/step - loss: 1.2335 - accuracy: 0.6559 - val_loss: 1.7934 - val_accuracy: 0.5539\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 7s 109ms/step - loss: 1.2051 - accuracy: 0.6574 - val_loss: 1.7485 - val_accuracy: 0.5599\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 7s 109ms/step - loss: 1.2135 - accuracy: 0.6544 - val_loss: 1.7770 - val_accuracy: 0.5402\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 1.1572 - accuracy: 0.6786 - val_loss: 1.6860 - val_accuracy: 0.5812\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 1.1466 - accuracy: 0.6604 - val_loss: 1.6107 - val_accuracy: 0.5857\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 1.0862 - accuracy: 0.6822 - val_loss: 1.7895 - val_accuracy: 0.5463\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 1.1005 - accuracy: 0.6903 - val_loss: 1.6844 - val_accuracy: 0.5675\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 7s 109ms/step - loss: 1.0926 - accuracy: 0.6781 - val_loss: 1.6965 - val_accuracy: 0.5387\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 1.0539 - accuracy: 0.7004 - val_loss: 1.7104 - val_accuracy: 0.5873\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 1.0419 - accuracy: 0.6994 - val_loss: 1.6546 - val_accuracy: 0.5812\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 1.0042 - accuracy: 0.7146 - val_loss: 1.6943 - val_accuracy: 0.5645\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 1.0004 - accuracy: 0.7126 - val_loss: 1.7190 - val_accuracy: 0.5918\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 1.0148 - accuracy: 0.7065 - val_loss: 1.7552 - val_accuracy: 0.5630\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.9488 - accuracy: 0.7298 - val_loss: 1.6838 - val_accuracy: 0.5721\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.9427 - accuracy: 0.7348 - val_loss: 1.7020 - val_accuracy: 0.5615\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.9452 - accuracy: 0.7384 - val_loss: 1.8416 - val_accuracy: 0.5326\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 1.0043 - accuracy: 0.7075 - val_loss: 1.8484 - val_accuracy: 0.5144\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.8719 - accuracy: 0.7510 - val_loss: 1.6275 - val_accuracy: 0.5903\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.8617 - accuracy: 0.7657 - val_loss: 1.6770 - val_accuracy: 0.5918\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 0.8786 - accuracy: 0.7627 - val_loss: 1.6797 - val_accuracy: 0.5964\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 7s 105ms/step - loss: 0.8254 - accuracy: 0.7723 - val_loss: 1.6593 - val_accuracy: 0.5797\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.8204 - accuracy: 0.7627 - val_loss: 1.9328 - val_accuracy: 0.5190\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.8773 - accuracy: 0.7616 - val_loss: 1.7789 - val_accuracy: 0.5615\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.8095 - accuracy: 0.7799 - val_loss: 1.7693 - val_accuracy: 0.5781\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.7760 - accuracy: 0.7824 - val_loss: 1.7233 - val_accuracy: 0.5857\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 7s 105ms/step - loss: 0.8216 - accuracy: 0.7611 - val_loss: 1.9095 - val_accuracy: 0.5341\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 0.8461 - accuracy: 0.7515 - val_loss: 1.8201 - val_accuracy: 0.5690\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.7813 - accuracy: 0.7809 - val_loss: 1.7980 - val_accuracy: 0.5873\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.7409 - accuracy: 0.7940 - val_loss: 1.7171 - val_accuracy: 0.5873\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 0.7404 - accuracy: 0.7890 - val_loss: 1.8186 - val_accuracy: 0.5933\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 7s 118ms/step - loss: 0.6773 - accuracy: 0.8193 - val_loss: 1.7803 - val_accuracy: 0.5690\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 8s 122ms/step - loss: 0.6949 - accuracy: 0.8163 - val_loss: 1.8674 - val_accuracy: 0.5797\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 8s 126ms/step - loss: 0.7331 - accuracy: 0.7874 - val_loss: 1.8412 - val_accuracy: 0.5706\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.6493 - accuracy: 0.8138 - val_loss: 1.8209 - val_accuracy: 0.5918\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 0.6627 - accuracy: 0.8249 - val_loss: 1.9042 - val_accuracy: 0.5660\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 0.6773 - accuracy: 0.8087 - val_loss: 1.8220 - val_accuracy: 0.5888\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 0.6479 - accuracy: 0.8214 - val_loss: 1.9518 - val_accuracy: 0.5615\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.6846 - accuracy: 0.8122 - val_loss: 1.8989 - val_accuracy: 0.5857\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.6569 - accuracy: 0.8259 - val_loss: 1.7526 - val_accuracy: 0.5766\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 0.5816 - accuracy: 0.8456 - val_loss: 1.8501 - val_accuracy: 0.6146\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.5936 - accuracy: 0.8406 - val_loss: 1.9181 - val_accuracy: 0.5615\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.6358 - accuracy: 0.8249 - val_loss: 1.9486 - val_accuracy: 0.5933\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.5867 - accuracy: 0.8370 - val_loss: 1.9431 - val_accuracy: 0.5766\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.5497 - accuracy: 0.8618 - val_loss: 1.9092 - val_accuracy: 0.5933\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 0.5342 - accuracy: 0.8644 - val_loss: 2.0497 - val_accuracy: 0.5630\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.5973 - accuracy: 0.8335 - val_loss: 1.8898 - val_accuracy: 0.5933\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.5755 - accuracy: 0.8487 - val_loss: 1.9605 - val_accuracy: 0.5873\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 0.5681 - accuracy: 0.8456 - val_loss: 2.0841 - val_accuracy: 0.5599\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.5478 - accuracy: 0.8568 - val_loss: 2.0035 - val_accuracy: 0.5903\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.5181 - accuracy: 0.8679 - val_loss: 2.0689 - val_accuracy: 0.5979\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.5385 - accuracy: 0.8593 - val_loss: 2.1078 - val_accuracy: 0.6055\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 0.5624 - accuracy: 0.8472 - val_loss: 2.0868 - val_accuracy: 0.5888\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 0.4877 - accuracy: 0.8780 - val_loss: 2.0070 - val_accuracy: 0.5873\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 7s 108ms/step - loss: 0.5202 - accuracy: 0.8689 - val_loss: 1.9594 - val_accuracy: 0.5873\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.5225 - accuracy: 0.8694 - val_loss: 2.1290 - val_accuracy: 0.5781\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 0.4966 - accuracy: 0.8674 - val_loss: 2.3333 - val_accuracy: 0.5493\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.5572 - accuracy: 0.8436 - val_loss: 2.1132 - val_accuracy: 0.5964\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 0.4534 - accuracy: 0.8932 - val_loss: 2.1098 - val_accuracy: 0.6055\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.4407 - accuracy: 0.8993 - val_loss: 2.0798 - val_accuracy: 0.6024\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 0.4472 - accuracy: 0.8887 - val_loss: 2.0491 - val_accuracy: 0.5827\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.4437 - accuracy: 0.8978 - val_loss: 2.1058 - val_accuracy: 0.5948\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 7s 106ms/step - loss: 0.4641 - accuracy: 0.8821 - val_loss: 2.0953 - val_accuracy: 0.5994\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 7s 107ms/step - loss: 0.4200 - accuracy: 0.8978 - val_loss: 2.1468 - val_accuracy: 0.5903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f55dab8e280>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "NN = Sequential()\n",
    "\n",
    "NN.add(InputLayer(input_shape=X_train.shape[1:]))\n",
    "\n",
    "\n",
    "NN.add(Conv2D(filters=30, kernel_size=3, activation='relu', padding='same'))\n",
    "\n",
    "NN.add(MaxPooling2D())\n",
    "\n",
    "\n",
    "NN.add(Conv2D(filters=60, kernel_size=3, activation='relu', padding='same'))\n",
    "\n",
    "NN.add(MaxPooling2D())\n",
    "\n",
    "\n",
    "NN.add(Conv2D(filters=90, kernel_size=3, activation='relu', padding='same'))\n",
    "\n",
    "NN.add(GlobalAveragePooling2D())\n",
    "\n",
    "\n",
    "NN.add(Flatten())\n",
    "\n",
    "NN.add(Dense(80, activation='relu', kernel_regularizer='l2'))\n",
    "\n",
    "NN.add(Dropout(0.05)) #added dropout here\n",
    "\n",
    "NN.add(Dense(40, activation='softmax'))  # 40 target classes\n",
    "\n",
    "NN.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "NN.summary()\n",
    "NN.fit(X_train, y_train_cat, epochs=100, verbose=1, validation_split=0.25,\n",
    "       callbacks=[\n",
    "           keras.callbacks.ModelCheckpoint(\n",
    "               'models/mnist.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "               save_best_only=True)\n",
    "       ])  # track progress as we fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "398910c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b09062",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
